{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "# import unicodedata\n",
    "# from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "How you want the text to be read from the file. Add additional changes you want to make to the file before trying the NLP. \n",
    "       The first one joins all groups of consecutive lines together, so\n",
    "\n",
    "        Doe, John. Columbia University\n",
    "        12345 N. 1st St.\n",
    "        BA, 1921\n",
    "\n",
    "        Miller, Sue. Columbia University\n",
    "        12345 N. 2nd St.\n",
    "        BS, 1922\n",
    "\n",
    "        ----->\n",
    "\n",
    "        Doe, John. Columbia University 12345 N. 1st St. BA, 1921\n",
    "        Miller, Sue. Columbia University 12345 N. 2nd St. BS, 1922\n",
    "\n",
    "That makes writing a regex easier if your .txt files look like the above. If they already look like the output of this function, then you can run the other pre-process cell instead.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(fname):\n",
    "    with open(fname, encoding='utf-8') as fin:\n",
    "        lines = re.sub(r'(.)\\-\\n(.)', lambda x : x.group(1) + x.group(2), fin.read()).split('\\n')\n",
    "    return re.sub(r'([^\\n])\\n', lambda x : x.group(1) + ' ', '\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An alternate pre-processing function that just reads lines. Only run one of these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(fname):\n",
    "    with open(fname, encoding='utf-8') as fin:\n",
    "        lines = fin.read()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that makes lists of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(text):\n",
    "    \"\"\"Collects all names and returns a formatted list of matches from text<str>.\"\"\"  \n",
    "    if type(text) is not str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # This loop looks through lines (from above) and appends each match to a list, formatted the way we want\n",
    "    matches = []\n",
    "    non_matches = []\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        i = people_re.search(line)\n",
    "        if i is not None:\n",
    "            matches.append((i.groupdict()['first'].strip() + ' ' + i.groupdict()['last'].strip(), i.groupdict()['info']))\n",
    "#             matches.append((i.groupdict()['first'], i.groupdict()['last'], i.groupdict()['class'], i.groupdict()['info']))\n",
    "#             matches.append(tuple(i.groupdict().values()))\n",
    "        else:\n",
    "            non_matches.append(line)\n",
    "    \n",
    "    return matches, non_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the regex and which school to search\n",
    "Go to https://pythex.org/ to test your regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_re = re.compile(r'(?P<last>([a-z]+)), (?P<first>[a-z ]+) (?P<info>.*)', flags=re.IGNORECASE)\n",
    "\n",
    "# Name of the school\n",
    "source = \"Columbia\"\n",
    "\n",
    "# Name of the csv file to write to\n",
    "target = f\"NLP_Output_{source}.csv\"\n",
    "\n",
    "# This is where the non-matched lines will be written\n",
    "chk_file = 'check.csv'\n",
    "\n",
    "os.chdir(r'..\\output\\University CSVs\\{}'.format(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this just to make sure that if you rerun the code,\n",
    "# it makes a new file instead of appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e1fbfb30c890>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Update target file name so that we aren't appending to an existing file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "# Update target file name so that we aren't appending to an existing file\n",
    "    \n",
    "if os.path.exists(target):\n",
    "    i = 1\n",
    "    name, ext = target.split('.')\n",
    "    while os.path.exists(f'{name}_{i}.{ext}'):\n",
    "        i += 1\n",
    "    target = f'{name}_{i}.{ext}'\n",
    "\n",
    "if os.path.exists(chk_file):\n",
    "    i = 1\n",
    "    name, ext = chk_file.split('.')\n",
    "    while os.path.exists(f'{name}_{i}.{ext}'):\n",
    "        i += 1\n",
    "    chk_file = f'{name}_{i}.{ext}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "If you interrupt this cell or the previous one and the next run gives an OS error, restart the kernel and then try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f1c6e1813252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'..\\..\\University Text Files\\{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# This is where the work happens. Uses the collect() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'finding names in {txt}...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(r'..\\..\\University Text Files\\{}'.format(source))\n",
    "for txt in [i for i in os.listdir() if i[-4:] == '.txt']:\n",
    "    # This is where the work happens. Uses the collect() function.\n",
    "    print(f'finding names in {txt}...')\n",
    "    result, check = collect(pre_process(txt))\n",
    "    num = len(result)\n",
    "    print(f'found {num} names. Writing to file {target}...')\n",
    "    os.chdir(r'..\\..\\University CSVs\\{}'.format(source))\n",
    "\n",
    "    # Write matches to the target file (.csv)\n",
    "    with open(target, 'a') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(['Name', 'Address(es)'])#, 'State', 'School', 'Additional Degrees', 'Year found'])\n",
    "\n",
    "        # Write the names, addresses, and year found\n",
    "        for match in result:\n",
    "            writer.writerow([i for i in match] + [txt[-8:-4]])\n",
    "\n",
    "        # Total names found that year\n",
    "        writer.writerow(['Names found:', num])\n",
    "\n",
    "    # Write non-matches to the check file\n",
    "    with open(chk_file, 'a') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        for i in check:\n",
    "            try:\n",
    "                writer.writerow([i])\n",
    "            except UnicodeEncodeError:\n",
    "                writer.writerow([\"Error on line\"])\n",
    "\n",
    "    os.chdir(r'..\\..\\University Text Files\\{}'.format(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
