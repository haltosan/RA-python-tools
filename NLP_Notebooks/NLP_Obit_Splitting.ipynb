{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs (in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook splits one big input file into multiple sections, as determined by a regex (ex. splitting up obituary OCR by image). Then it runs all the specified regular expressions on each section. You can find all matches of a regex in the section (findall) or just the first match (search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "# import unicodedata\n",
    "# from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Other Preliminary Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the lines in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(fname):\n",
    "    with open(fname, encoding='utf-8') as fin:\n",
    "        lines = fin.read()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split text by the image it came from\n",
    "\n",
    "Todo: define the regex you want to use to split the file into different entries, and turn on/off the option to delete the last string in the list (depending on the format of the input, may always be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input(text):\n",
    "    \"\"\"Splits text into different strings, using a regex as a seperator\"\"\"  \n",
    "    if type(text) is not str:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # CHANGE THE REGEX STRING IN THE LINE BELOW IF YOU WANT TO SEPARATE THE TEXT DIFFERENTLY\n",
    "    split_re = r'--- PAGE END ---'\n",
    "    split_strings = re.split(split_re, text)\n",
    "    \n",
    "    # IF EACH SECTION WILL HAVE A MATCH FOR SPLIT_RE AT THE END, RUN THIS TO DELETE THE LAST STRING IN THE LIST (WILL BE EMPTY)\n",
    "    last_is_empty = True\n",
    "    if last_is_empty and len(split_strings) > 0:\n",
    "        del split_strings[-1] # removes empty string at the end\n",
    "    return split_strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give file information\n",
    "\n",
    "Todo: name the output file and give paths for the input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GIVE A NAME FOR THE OUTPUT FILE HERE (not a path, just something recognizable)\n",
    "output_name = \"adjusted_NLP\"\n",
    "\n",
    "# Name of the csv file to write to\n",
    "target = f\"{output_name}.csv\"\n",
    "\n",
    "# PUT INPUT FOLDER HERE\n",
    "INPUT_PATH = r'V:\\FHSS-JoePriceResearch\\papers\\current\\tree_growth\\US\\Skagit\\skagit_obits\\2_NLP\\Adjusted_Input'\n",
    "\n",
    "# PUT OUTPUT FOLDER HERE\n",
    "OUTPUT_PATH = r'V:\\FHSS-JoePriceResearch\\papers\\current\\tree_growth\\US\\Skagit\\skagit_obits\\2_NLP\\Adjusted_Output'\n",
    "\n",
    "os.chdir(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Makes the output replace the previous file, instead of appending to the previous file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update target file name so that we aren't appending to an existing file\n",
    "    \n",
    "if os.path.exists(target):\n",
    "    i = 1\n",
    "    name, ext = target.split('.')\n",
    "    while os.path.exists(f'{name}_{i}.{ext}'):\n",
    "        i += 1\n",
    "    target = f'{name}_{i}.{ext}'\n",
    "\n",
    "# (took out code for the check file; don't know how to create one with this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Regex\n",
    "Go to https://regex101.com/ to test your regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search regex\n",
    "Will return only the first match in each entry\n",
    "\n",
    "Todo: Define regular expressions for which you want to use the search technique, and add them to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex\n",
    "#image_re = re.compile(r'(?<=-image:)(?P<imageName>[^\\n]+)')  # not as efficient, but will only capture image name\n",
    "\n",
    "# Add to list (so the program runs all of them on each entry), in the order you want the columns to be\n",
    "search_regex_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findall regex\n",
    "Will return a semicolon-separated list of all matches in the entry\n",
    "\n",
    "Todo: Define regular expressions for which you want to use the findall technique, and add them to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex\n",
    "date_re = re.compile(r'(?P<month>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\.? (?P<day>\\d{1,2})(?:, (?P<year>\\d{4}))?')\n",
    "name_re = re.compile(r'(?P<firstNames>(?:[\\'\\\"]?[A-Z][\\'\\\"A-Za-z]+ )+(?:[A-Z]. )*)(?P<lastName>[A-Z][\\'A-Za-z]+)')\n",
    "\n",
    "# Add to list\n",
    "findall_regex_list = [date_re, name_re]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-separated regex\n",
    "Uses search, but will output each named capturing group in its own column\n",
    "\n",
    "Todo: Define regular expressions for which you want to have each named capturing group separated, and add them to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex\n",
    "image_re = re.compile(r'-image:(?P<imageName>[^\\n]+)')\n",
    "death_date_re = re.compile(r'(?P<month>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\.? (?P<day>\\d{1,2})(?:, (?P<year>\\d{4}))')\n",
    "\n",
    "# Add to list\n",
    "separated_regex_list = [image_re, name_re, death_date_re]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define column names (will be printed at top of file)\n",
    "The regex matches will be outputted in the following order:\n",
    "  Group-separated regex, beginning of list to end of list\n",
    "  Search regex, beginning of list to end of list\n",
    "  Findall regex, beginning of list to end of list\n",
    "  \n",
    "If you want column names printed at the top, write the titles you want in order here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Image','First_Names', 'Last_Names', 'Dates', 'Names_or_Places']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run search regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_regex(text):\n",
    "    \n",
    "    # list that holds the matches of all the search regex (ex. information like name)\n",
    "    matches = []\n",
    "    \n",
    "    # iterate through all the search regex, and add its matches to the overall list\n",
    "    for regex in search_regex_list:\n",
    "        re_match = re.search(regex, text) # finds the first match\n",
    "        if re_match:\n",
    "            matches.append(re_match.group().replace('\\n', ' ')) # if match exists, add the string of the match to the list without newlines\n",
    "        else:\n",
    "            matches.append(\"\") # makes an empty cell instead of shifting the row over\n",
    "            \n",
    "    return matches    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run findall regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findall_regex(text):\n",
    "    \n",
    "    # list that holds the matches of all the findall regex (ex. all dates)\n",
    "    findall_matches = []\n",
    "        \n",
    "      # iterate through all the search regex, adding any matches to the list\n",
    "    for regex in findall_regex_list:\n",
    "        match_iter = re.finditer(regex, text) # does the searching\n",
    "        combined_string = \"\" # string that will hold all the results from one regex\n",
    "        if match_iter:\n",
    "            for match in match_iter:\n",
    "                combined_string = combined_string + match.group() + \"; \"\n",
    "        findall_matches.append(combined_string.replace('\\n', ' '))\n",
    "            \n",
    "            \n",
    "    return findall_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run group-separated regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separated_regex(text):\n",
    "    \n",
    "    # list that holds the matches of all the group-separated regex (ex. information like names, split into given/surname).\n",
    "    # Each entry is a list of named subgroups\n",
    "    matches = []\n",
    "    \n",
    "    # iterate through all the search regex, and add its matches to the overall list\n",
    "    for regex in separated_regex_list:\n",
    "        re_match = re.search(regex, text) # finds the first match\n",
    "        if re_match:\n",
    "            re_dict = re_match.groupdict() # returns a dictionary of all named capturing groups\n",
    "            re_list = list(re_dict.values()) # get the values out of the key pairs\n",
    "            # take out newlines from the matches\n",
    "            for i in range(len(re_list)):\n",
    "                re_list[i] = re_list[i].replace('\\n', ' ')\n",
    "            matches.append(re_list)\n",
    "        # if it doesn't match, add the right number of empty cells to the row\n",
    "        else:\n",
    "            group_num = len(regex.groupindex)\n",
    "            empty_list = []\n",
    "            for i in range(group_num):\n",
    "                empty_list.append('')\n",
    "            matches.append(empty_list) # makes an empty cell instead of shifting the row over\n",
    "            \n",
    "    return matches   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding obituaries in 0-transcribed.txt...\n",
      "found 50 obituaries. Writing to file adjusted_NLP.csv...\n"
     ]
    }
   ],
   "source": [
    "# Find matches within the split text strings, and write those matches to the target file (.csv)\n",
    "\n",
    "os.chdir(OUTPUT_PATH)\n",
    "\n",
    "with open(target, 'a', newline='', encoding='utf-8-sig') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    # PUT SECTION HEADERS HERE IF YOU WANT THEM\n",
    "    writer.writerow(column_names)\n",
    "    \n",
    "    os.chdir(INPUT_PATH)\n",
    "    \n",
    "    for txt in [i for i in os.listdir() if i[-4:] == '.txt']:\n",
    "        os.chdir(INPUT_PATH)\n",
    "    \n",
    "        # Use the split_input() function to split the text document, so the OCR output for each source image is separate\n",
    "        print(f'finding obituaries in {txt}...')\n",
    "        split_strings = split_input(pre_process(txt))\n",
    "        num = len(split_strings)\n",
    "        print(f'found {num} obituaries. Writing to file {target}...')\n",
    "    \n",
    "        os.chdir(OUTPUT_PATH)\n",
    "        \n",
    "        # Run each regex on the OCR text from each image\n",
    "        for string in split_strings:\n",
    "            \n",
    "            all_matches = [] # list of strings that will become each entry in a row\n",
    "            \n",
    "            # Run group-separated regex, and add each group to the list\n",
    "            separated_matches = separated_regex(string)\n",
    "            if separated_matches is not None:\n",
    "                for match in separated_matches:\n",
    "                    all_matches.extend(match)\n",
    "            \n",
    "            # Run search regex, add the list of matches it returns to the combined match list\n",
    "            search_matches = search_regex(string)\n",
    "            if search_matches is not None:\n",
    "                #search_matches = search_matches if isinstance(search_matches, list) else [search_matches, \"test\"]\n",
    "                all_matches.extend(search_matches)\n",
    "            \n",
    "            # Run findall regex, add its matches to the list\n",
    "            findall_matches = findall_regex(string)\n",
    "            if findall_matches is not None:\n",
    "                all_matches.extend(findall_matches)\n",
    "        \n",
    "            # Write out the row\n",
    "            writer.writerow(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
