{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-File, Multi-Line Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer:\n",
    "This code uses the multi-line strategy mentioned in the \"NLP_Multi-Line\" notebook, so go there to get context. This notebook will probably work on OCR where all information is combined on one line -- but here the matches can extend over multiple lines, so make sure your regex does what you expect in multi-line mode. Also keep in mind that this notebook doesn't have an option to combine groups of consecutive lines into one line, like the original NLP notebook does. This code is experimental, so feel free to bug me (Sarah) if something isn't working (or just improve it yourself if you want)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When / How to Use\n",
    "\n",
    "This notebook allows you to automatically fill columns with certain values, and change those values when you switch to a new file. For example, if you have different files from different years, you can fill in the year column with 1921 for the 1921 file, 1922 for the 1922 file, and so on. You can also fill in columns that remain the same between all files, like university, state, Chetty tier, etc., so you don't have to do that manually later.\n",
    "\n",
    "Like before, I have the code you need to change labeled with comments in all caps. Most of the steps are the same as the multi-line notebook. You can make a copy of the notebook and alter those parts to work with your school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "# import unicodedata\n",
    "# from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads all lines instead of splicing them apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(fname):\n",
    "    with open(fname, encoding='utf-8') as fin:\n",
    "        lines = fin.read()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that makes lists of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(text):\n",
    "    \"\"\"Collects all names and returns a formatted list of matches from text<str>.\"\"\"  \n",
    "    if type(text) is not str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # This loop looks through lines (from above) and appends each match to a list, formatted the way we want\n",
    "    raw_matches = []\n",
    "    non_matches = []\n",
    "    \n",
    "    # Find all matches in the text and put it in a list\n",
    "    # raw_matches = people_re.findall(text, re.MULTILINE)\n",
    "    \n",
    "    for match in people_re.finditer(text, re.MULTILINE):\n",
    "        raw_matches.append(match)\n",
    "    \n",
    "    # Add everything that isn't in a match to non_matches (make substrings from the gaps in-between matches)\n",
    "    prev_end_index = 0\n",
    "    length = len(raw_matches)\n",
    "    for i in range(length):\n",
    "        currentMatch = raw_matches[i]\n",
    "        \n",
    "        # Get start and end values\n",
    "        matchSpan = currentMatch.span()\n",
    "        start = matchSpan[0]\n",
    "        end = matchSpan[1]\n",
    "        \n",
    "        non_matches.append(text[prev_end_index:start])\n",
    "        prev_end_index = end\n",
    "    # add last bit (last match to end of string)\n",
    "    non_matches.append(text[prev_end_index:-1])\n",
    "    \n",
    "    \n",
    "    return raw_matches, non_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the regex and which school to search\n",
    "Go to https://pythex.org/ to test your regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PUT REGULAR EXPRESSION HERE, (1/8)\n",
    "people_re = re.compile(r'(^(?P<studentName>[a-zA-Z -\\'’é]{7,}([A-Z]\\.)?[a-zA-Z -]+(, Jr\\.?)?)(, \\dd)?(\\n\\n[0-9]+[A-Za-z. -]+)?\\n\\n(?P<city>[a-zA-Z./ ]+)(, (?P<state>[a-zA-Z./ ]+))?)', flags=re.MULTILINE)\n",
    "\n",
    "# PUT NAME OF SCHOOL HERE (aka the name of the folder), (2/8)\n",
    "source = \"YaleTemp\"\n",
    "\n",
    "# Name of the csv file to write to\n",
    "target = f\"NLP_Output_{source}.csv\"\n",
    "\n",
    "# This is where the non-matched lines will be written\n",
    "chk_file = 'check.csv'\n",
    "\n",
    "os.chdir(r'..\\output\\University CSVs\\{}'.format(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this just to make sure that if you rerun the code,\n",
    "# it makes a new file instead of appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update target file name so that we aren't appending to an existing file\n",
    "    \n",
    "if os.path.exists(target):\n",
    "    i = 1\n",
    "    name, ext = target.split('.')\n",
    "    while os.path.exists(f'{name}_{i}.{ext}'):\n",
    "        i += 1\n",
    "    target = f'{name}_{i}.{ext}'\n",
    "\n",
    "if os.path.exists(chk_file):\n",
    "    i = 1\n",
    "    name, ext = chk_file.split('.')\n",
    "    while os.path.exists(f'{name}_{i}.{ext}'):\n",
    "        i += 1\n",
    "    chk_file = f'{name}_{i}.{ext}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function -- create rows and variables for each row, then output\n",
    "If you interrupt this cell or the previous one and the next run gives an OS error, restart the kernel and then try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding names in YaleTemp_1921.txt...\n",
      "found 953 names. Writing to file NLP_Output_YaleTemp_8.csv...\n",
      "finding names in YaleTemp_1922.txt...\n",
      "found 984 names. Writing to file NLP_Output_YaleTemp_8.csv...\n",
      "finding names in YaleTemp_1923.txt...\n",
      "found 1098 names. Writing to file NLP_Output_YaleTemp_8.csv...\n",
      "finding names in YaleTemp_1924.txt...\n",
      "found 1157 names. Writing to file NLP_Output_YaleTemp_8.csv...\n",
      "finding names in YaleTemp_1925.txt...\n",
      "found 1333 names. Writing to file NLP_Output_YaleTemp_8.csv...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'..\\..\\University Text Files\\{}'.format(source))\n",
    "\n",
    "# RENAME FILES SO THEY WILL BE READ IN THE ORDER YOU WANT (ex. 0_Yale_1923_Seniors, 1_Yale_1923_Juniors, etc.) (3/8)\n",
    "\n",
    "\n",
    "# LIST INITIAL HARDCODED COLUMN VALUES HERE (i.e. the values you want for the first file, index 0) (4/8)\n",
    "standing = ''\n",
    "year = '1921'\n",
    "school = 'Yale University'\n",
    "school_state = 'Connecticut'\n",
    "chetty_tier = '1'\n",
    "class_year = ''\n",
    "\n",
    "file_name = '1921 College' # this variable is only used on the debugging row to distinguish files in the output; comment out if you want\n",
    "\n",
    "index = 0;\n",
    "for txt in [i for i in os.listdir() if i[-4:] == '.txt']:\n",
    "    \n",
    "    # Change column values based on which file it is\n",
    "    \n",
    "    # CHANGE THE VARIABLES FOR THE NEW COLUMN OUTPUT FOR EACH FILE (5/8)\n",
    "    if (index == 1):\n",
    "        file_name = '1922 College'\n",
    "        year = '1922'\n",
    "        class_year = '' \n",
    "    elif (index == 2):\n",
    "        file_name = '1923 College'\n",
    "        year = '1923'\n",
    "        class_year = ''\n",
    "    elif (index == 3):\n",
    "        file_name = '1924 College'\n",
    "        year = '1924'\n",
    "        class_year = ''\n",
    "    elif (index == 4):\n",
    "        file_name = '1925 College'\n",
    "        year = '1925'\n",
    "        class_year = ''\n",
    "    # elif (index == #), and so on for each file\n",
    "    \n",
    "    \n",
    "    # This is where the work happens. Uses the collect() function.\n",
    "    print(f'finding names in {txt}...')\n",
    "    \n",
    "    result, check = collect(pre_process(txt))\n",
    "    num = len(result)\n",
    "    print(f'found {num} names. Writing to file {target}...')\n",
    "    os.chdir(r'..\\..\\University CSVs\\{}'.format(source))\n",
    "\n",
    "    # Write matches to the target file (.csv)\n",
    "    \n",
    "    with open(target, 'a', newline='', encoding='utf-8-sig') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        \n",
    "        \n",
    "        # PUT COLUMN HEADINGS HERE -- WILL ONLY BE AT TOP OF PAGE (6/8)\n",
    "        if (index == 0):\n",
    "            writer.writerow(['Name', 'City' , 'State', 'Standing', 'Year', 'Class_Year', 'School', 'School_State', 'Chetty_Tier'])\n",
    "            \n",
    "        # Output a line at the top of each file so you can tell them apart (for debugging, feel free to comment out)\n",
    "        writer.writerow(['FILE:', file_name])\n",
    "        \n",
    "\n",
    "        # Output each match in a row\n",
    "        for match in result:\n",
    "            # USE THIS SYNTAX TO MAKE VARIABLES FOR YOUR NAMED GROUPS, (7/8)\n",
    "            # variable_name = match.group('namedGroupInExpression')\n",
    "            name = match.group('studentName')\n",
    "            city = match.group('city')\n",
    "            state = match.group('state')\n",
    "            \n",
    "            \n",
    "            # PUT VARIABLE NAMES IN ORDER HERE TO OUTPUT THEM IN A ROW (8/8)\n",
    "            writer.writerow([name, city, state, standing, year, class_year, school, school_state, chetty_tier])\n",
    "            \n",
    "\n",
    "        # Total names found in file\n",
    "        writer.writerow(['Names found:', num])\n",
    "        index = index + 1;\n",
    "\n",
    "    # Write non-matches to the check file\n",
    "    with open(chk_file, 'a', newline='', encoding='utf-8-sig') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        for i in check:\n",
    "            try:\n",
    "                for line in i.split('\\n'):\n",
    "                    writer.writerow([line])\n",
    "            except UnicodeEncodeError as e:\n",
    "                writer.writerow([e])\n",
    "\n",
    "    os.chdir(r'..\\..\\University Text Files\\{}'.format(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
